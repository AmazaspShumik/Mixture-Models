# Mixture-of-Experts-Models

##  Hierarchical Mixture of Experts

Hierarchical mixture of experts can be used to solve standard [regression](https://github.com/AmazaspShumik/Mixture-of-Experts-Models/blob/master/Hierarchical%20Mixture%20of%20Experts/hme_standard_regression_examples.ipynb) and [classification](https://github.com/AmazaspShumik/Mixture-of-Experts-Models/blob/master/Hierarchical%20Mixture%20of%20Experts/hme_classification_examples.ipynb) problems, however one of the main applications of hme are problems with [multimodal output](https://github.com/AmazaspShumik/Mixture-of-Experts-Models/blob/master/Hierarchical%20Mixture%20of%20Experts/hme_multimodal_output_examples.ipynb).


##  Mixture Discriminant Analysis 

Mixture Discriminant Analysis is generative classification algorithm, that assumes each class is generated by mixture of gaussians. To restrict complexity of model and avoid singularities while fitting GMM MDA assumes that all of the gaussians share same covariance. You can find code for MDA [here](https://github.com/AmazaspShumik/Mixture-Models/blob/master/Mixture%20Discriminant%20Analysis/mda.py) and demo [here](https://github.com/AmazaspShumik/Mixture-Models/blob/master/Mixture%20Discriminant%20Analysis/mda_demo.ipynb)

##  Bernoulli Mixture Model


## Multinomial Mixture Model

## Mixture Density Neural Network




